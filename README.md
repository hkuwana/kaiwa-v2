# ğŸ¯ Kaiwa v2 - Conversation Practice with AI

> **7-Day MVP**: A functional, kernel-first conversation practice app built with SvelteKit and OpenAI.

[![SvelteKit](https://img.shields.io/badge/SvelteKit-FF3E00?style=for-the-badge&logo=svelte&logoColor=white)]()
[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)]()
[![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white)]()

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ and pnpm
- OpenAI API key (optional for development)

### Installation

```bash
# Clone and install
git clone <your-repo>
cd kaiwa
pnpm install

# Set up environment
cp .env.example .env.local
# Edit .env.local with your OpenAI API key

# Start development server
pnpm dev
```

Visit `http://localhost:5173` and start speaking! ğŸ¤

## ğŸ—ï¸ Architecture Overview

### Kernel-First Design

```
src/
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ kernel/           # ğŸ§  Pure functional core
â”‚   â”‚   â”œâ”€â”€ index.ts      # Conversation state machine
â”‚   â”‚   â””â”€â”€ adapters.ts   # External service interfaces
â”‚   â”œâ”€â”€ orchestrator.ts   # ğŸ­ Coordinates kernel + adapters
â”‚   â”œâ”€â”€ components/       # ğŸ¨ UI components
â”‚   â””â”€â”€ utils/           # ğŸ› ï¸ Utility functions
â”œâ”€â”€ routes/
â”‚   â”œâ”€â”€ +page.svelte     # ğŸ“± Main conversation UI
â”‚   â””â”€â”€ api/             # ğŸ”Œ API endpoints
â””â”€â”€ app.html             # ğŸ“„ HTML template
```

### Key Principles

- **Functional Core**: All business logic is pure functions
- **Imperative Shell**: Side effects handled at edges
- **Single State Tree**: One source of truth
- **Progressive Enhancement**: Works without JavaScript

## ğŸ¯ Features

### âœ… Day 1-2 (Kernel)

- [x] Audio recording with browser APIs
- [x] OpenAI Whisper transcription
- [x] GPT conversation responses
- [x] Text-to-speech playback
- [x] Pure functional state management

### âœ… Day 3-4 (Experience)

- [x] Beautiful, responsive UI
- [x] Real-time conversation display
- [x] Visual recording indicators
- [x] Error handling and fallbacks

### ğŸš§ Day 5-6 (Enhancement)

- [ ] Optional Google OAuth
- [ ] Conversation persistence
- [ ] Progress tracking
- [ ] Cloud storage sync

### ğŸ“‹ Day 7 (Launch)

- [ ] Production deployment
- [ ] Performance optimization
- [ ] User testing
- [ ] Launch announcement

## ğŸ”§ Configuration

### Environment Variables

```bash
# Required for full functionality
OPENAI_API_KEY=sk-...

# Optional
DATABASE_URL=postgresql://...
GOOGLE_CLIENT_ID=...
GOOGLE_CLIENT_SECRET=...
SESSION_SECRET=your-secret-here
```

### API Endpoints

- `POST /api/transcribe` - Audio â†’ Text (Whisper)
- `POST /api/chat` - Text â†’ AI Response (GPT)
- `POST /api/tts` - Text â†’ Audio (OpenAI TTS)

## ğŸ¨ Usage Examples

### Basic Conversation

```typescript
import { createConversationStore } from '$lib/orchestrator';

const conversation = createConversationStore();

// Start conversation
await conversation.startConversation();

// Toggle recording
await conversation.toggleRecording();

// Access reactive state
console.log(conversation.state.messages);
```

### Custom Adapters

```typescript
import { ConversationOrchestrator } from '$lib/orchestrator';
import { myCustomAudioAdapter } from './adapters';

const orchestrator = new ConversationOrchestrator(
 myCustomAudioAdapter, // Custom audio handling
 adapters.ai, // Default AI adapter
 adapters.storage // Default storage
);
```

## ğŸ§ª Testing

```bash
# Type checking
pnpm check

# Unit tests (when implemented)
pnpm test

# E2E tests
pnpm test:e2e

# Linting
pnpm lint
```

## ğŸš€ Deployment

### Vercel (Recommended)

```bash
# Install Vercel CLI
npm i -g vercel

# Deploy
vercel

# Set environment variables in Vercel dashboard
```

### Other Platforms

The app is a standard SvelteKit app and can be deployed to:

- Netlify
- Cloudflare Pages
- Node.js servers
- Docker containers

## ğŸ” Troubleshooting

### Common Issues

**"No microphone access"**

- Grant microphone permissions in browser
- Use HTTPS (required for mic access)

**"Transcription not working"**

- Check OPENAI_API_KEY in environment
- Verify API key has credits
- Check browser console for errors

**"Audio not playing"**

- Check browser audio permissions
- Verify speakers/headphones connected
- Try different browser

### Development Mode

Without OpenAI API key, the app runs in fallback mode:

- Transcription returns test messages
- AI responses are hardcoded
- TTS falls back to browser speech synthesis

## ğŸ“š Documentation

- [Architecture Guide](docs/FEATURE_ARCHITECTURE.md)
- [Design Principles](docs/DESIGN_PRINCIPLES.md)
- [Migration Plan](docs/CTO_ASSESSMENT_MIGRATION_PLAN.md)

## ğŸ¤ Contributing

This is a 7-day MVP sprint. Focus areas:

1. **Core Functionality**: Conversation loop reliability
2. **User Experience**: Smooth, delightful interactions
3. **Error Handling**: Graceful fallbacks
4. **Performance**: Fast, responsive UI

## ğŸ“„ License

MIT - Build amazing conversation experiences! ğŸ‰

---

**ğŸ¯ MVP Goal**: Ship a magical conversation experience in 7 days. Everything else is enhancement.
